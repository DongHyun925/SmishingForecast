
import os
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from huggingface_hub import HfApi, HfFolder, create_repo

# ì„¤ì •
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__))) # í”„ë¡œì íŠ¸ ë£¨íŠ¸ (scripts/.. => root)
MODEL_NAME = "klue/roberta-base"
WEIGHTS_PATH = os.path.join(BASE_DIR, "models", "smishing_detector_model.pth")
REPO_ID = "donghyun95/smishing-detection-roberta-base"
COMMIT_MESSAGE = "Upload fine-tuned smishing detection model"

def deploy():
    print(f"[*] Base Model ë¡œë”© ì¤‘: {MODEL_NAME}...")
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)
    
    # ê°€ì¤‘ì¹˜ ë¡œë“œ
    if os.path.exists(WEIGHTS_PATH):
        print(f"[*] Fine-tuned ê°€ì¤‘ì¹˜ ë¡œë“œ ì¤‘: {WEIGHTS_PATH}")
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model.load_state_dict(torch.load(WEIGHTS_PATH, map_location=device))
    else:
        print(f"[!] ê°€ì¤‘ì¹˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {WEIGHTS_PATH}")
        print("    ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì€ ìƒíƒœì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ë¨¼ì € í•™ìŠµì„ ì§„í–‰í•´ì£¼ì„¸ìš”.")
        return

    # ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = "./hf_model_upload"
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"[*] ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì €ì¥ ì¤‘: {output_dir}")
    model.save_pretrained(output_dir)
    tokenizer.save_pretrained(output_dir)
    
    # Model Card ìƒì„±
    readme_content = f"""---
language: kr
tags:
- smishing
- security
- classification
- roberta
pipeline_tag: text-classification
---

# Smishing Detection Model (RoBERTa-Base)

ì´ ëª¨ë¸ì€ í•œêµ­ì–´ ìŠ¤ë¯¸ì‹± íƒì§€ë¥¼ ìœ„í•´ `klue/roberta-base`ë¥¼ íŒŒì¸íŠœë‹í•œ ëª¨ë¸ì…ë‹ˆë‹¤.

## Model Details
- **Base Model:** klue/roberta-base
- **Fine-tuning Data:** Synthesized Smishing/Ham Dataset + Self-Evolution via Adversarial Training
- **Author:** donghyun95
- **Task:** Binary Classification (0: Normal, 1: Smishing)

## Usage
```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

model_name = "{REPO_ID}"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

text = "ì—„ë§ˆ ë‚˜ í° ì•¡ì • ê¹¨ì¡Œì–´ ê¸‰í•˜ê²Œ ì†¡ê¸ˆí•´ì¤˜"
inputs = tokenizer(text, return_tensors="pt")

with torch.no_grad():
    logits = model(**inputs).logits
    probs = torch.softmax(logits, dim=1)
    print(f"Smishing Probability: {{probs[0][1].item()*100:.2f}}%")
```
"""
    with open(os.path.join(output_dir, "README.md"), "w", encoding="utf-8") as f:
        f.write(readme_content)
        
    print("[*] Hugging Face Hub ì—…ë¡œë“œ ì¤€ë¹„ ì™„ë£Œ.")
    
    # í† í° í™•ì¸
    token = HfFolder.get_token()
    if token is None:
        print("\n[!] Hugging Face ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        print("    í„°ë¯¸ë„ì—ì„œ `huggingface-cli login`ì„ ì‹¤í–‰í•˜ê±°ë‚˜, ì•„ë˜ì— í† í°ì„ ì…ë ¥í•˜ì„¸ìš”.")
        token_input = input("    Enter your Hugging Face Write Token (or press Enter to skip): ").strip()
        if token_input:
            token = token_input
            HfFolder.save_token(token)
        else:
            print("[!] ì—…ë¡œë“œë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤. ë¡œê·¸ì¸ í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return

    try:
        print(f"[*] Hubì— ì—…ë¡œë“œ ì¤‘... Target: {REPO_ID}")
        api = HfApi()
        
        # Repo ìƒì„± (ì—†ìœ¼ë©´ ìƒì„±, ìˆìœ¼ë©´ ë¬´ì‹œ)
        create_repo(repo_id=REPO_ID, token=token, exist_ok=True, private=False)
        
        # í´ë” ì—…ë¡œë“œ
        api.upload_folder(
            folder_path=output_dir,
            repo_id=REPO_ID,
            commit_message=COMMIT_MESSAGE,
            token=token
        )
        print(f"\n[SUCCESS] ëª¨ë¸ ì—…ë¡œë“œ ì™„ë£Œ! ğŸš€")
        print(f"ğŸ‘‰ https://huggingface.co/{REPO_ID}")
        
    except Exception as e:
        print(f"\n[ERROR] ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    deploy()
