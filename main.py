import os
import sys
import json
import random
from datetime import datetime

# ëª¨ë“ˆ ë¡œë“œ ë¡œì§
try:
    from src.planner import SmishingPlanner
    from src.generator import SmishingGenerator
    from src.intent_analyzer import IntentAnalyzer
    from src.detector import SmishingDetector
    from src.trainer import SmishingTrainer
    from src.utils import load_jsonl
except Exception as e:
    print(f"[Critical Error] ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    sys.exit(1)

def is_valid_attack_message(message):
    """
    ìƒì„±ëœ ë¬¸êµ¬ê°€ LLMì˜ ê±°ì ˆ ì‘ë‹µì¸ì§€, í˜¹ì€ ë¬¼ë¦¬ì ìœ¼ë¡œ ìœ íš¨í•œ ê³µê²© ìƒ˜í”Œì¸ì§€ ê²€ì¦
    """
    # 1. LLMì˜ ëŒ€í‘œì ì¸ ê±°ì ˆ íŒ¨í„´ (Safety Refusal)
    refusal_patterns = [
        "ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "ë„ì™€ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "ì£„ì†¡í•˜ì§€ë§Œ", 
        "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜", "ë¶€ì ì ˆí•œ ìš”ì²­", "ì •ì±…ì— ë”°ë¼", "ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
    ]
    if any(pattern in message for pattern in refusal_patterns):
        return False, "LLM Safety Refusal"
    
    # 2. êµ¬ì¡°ì  ìœ íš¨ì„± ê²€ì‚¬
    clean_msg = message.replace(" ", "")
    if len(clean_msg) < 10:
        return False, "Too Short Message"
        
    return True, "Valid"

def run_pipeline():
    print("\n" + "="*75)
    print("      [SELF-EVOLVING DEFENSE SYSTEM: SMART DATA VALIDATION]")
    print("="*75)

    planner = SmishingPlanner()
    generator = SmishingGenerator()
    intent_analyzer = IntentAnalyzer()
    
    DETECTION_THRESHOLD = 0.8
    EVOLUTION_THRESHOLD = 0.95 
    
    detector = SmishingDetector(threshold=DETECTION_THRESHOLD)
    trainer = SmishingTrainer(detector)
    
    data_path = "data/smishing_context_data.jsonl"
    scenarios_data = load_jsonl(data_path)
    if not scenarios_data: return

    sample_news = random.choice(scenarios_data)
    final_logs = []
    vulnerability_logs = []

    print(f"\n[Step 1] ë‰´ìŠ¤ ë¶„ì„: {sample_news['context']['news_title']}")
    attack_strategies = planner.plan_multiple_scenarios(sample_news, count=3)

    for i, strategy in enumerate(attack_strategies):
        print(f"\n[Scenario {i+1}] {strategy['strategy_name']}")
        
        # 1. ë¬¸êµ¬ ìƒì„± (ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ê°€ ì ìš©ëœ generator í˜¸ì¶œ)
        attack_msg = generator.generate_attack_message(strategy)
        
        # [ì¶”ê°€] ìƒì„±ëœ ë¬¸êµ¬ì˜ ìœ íš¨ì„± ì¦‰ì‹œ ê²€ì¦
        is_valid, validation_reason = is_valid_attack_message(attack_msg)
        if not is_valid:
            print(f" âš ï¸ ìƒì„± ì‹¤íŒ¨: {validation_reason} (ë¬¸êµ¬: {attack_msg[:20]}...)")
            continue

        # 2. ì˜ë„ ë° ìœ„í—˜ë„ ë¶„ì„
        analysis_res = intent_analyzer.analyze_intent(attack_msg)
        
        # 3. ë°©ì–´ ê²€ì¦
        detection_res = detector.predict(attack_msg)
        smishing_score = detection_res['smishing_score']
        
        # 4. êµ¬ì¡°ì  í•„í„°ë§ (í’ˆì§ˆ ê²€ì‚¬)
        has_url = any(x in attack_msg.lower() for x in ["http", "bit.ly", "t.me", "/", ".com", ".kr"])
        is_nonsense = smishing_score < 0.25 

        # 5. ìê°€ ì§„í™” íŒë‹¨ ë¡œì§
        should_train = False
        evolution_reason = ""

        if not detection_res['is_smishing']:
            should_train = True
            evolution_reason = "Detection Failed (Critical)"
        elif smishing_score < EVOLUTION_THRESHOLD:
            should_train = True
            evolution_reason = f"Low Confidence Defense (Score: {smishing_score:.4f})"

        # ìµœì¢… ì í•©ì„± íŒë‹¨ (ì§§ì€ ë¬¸êµ¬ì—¬ë„ URLì´ ìˆìœ¼ë©´ í•™ìŠµ ê°€ì¹˜ ìˆìŒ)
        if should_train and (is_nonsense or (len(attack_msg.replace(" ","")) < 15 and not has_url)):
            should_train = False
            evolution_reason = "Low Information Density"

        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "generated_message": attack_msg,
            "intent_analysis": analysis_res,
            "defense_result": detection_res,
            "evolution_target": should_train,
            "evolution_reason": evolution_reason if should_train else "Hardened"
        }
        final_logs.append(log_entry)

        print(f" > ë¬¸êµ¬: \"{attack_msg}\"")
        if should_train:
            print(f" ğŸš¨ ì·¨ì•½ì  ê°ì§€: {evolution_reason} -> ì ëŒ€ì  ì¬í•™ìŠµ ìˆ˜í–‰")
            vulnerability_logs.append(log_entry)
            
            temp_path = "data/vulnerabilities_temp.json"
            with open(temp_path, "w", encoding="utf-8") as f:
                json.dump([log_entry], f, indent=4, ensure_ascii=False)
            trainer.train_on_vulnerabilities(temp_path)
            os.remove(temp_path)
        else:
            final_status = "Perfect" if detection_res['is_smishing'] else "Invalid/Noise"
            print(f" ğŸ›¡ï¸ í•™ìŠµ ì œì™¸ ({final_status})")

    # 7. ê²°ê³¼ ì €ì¥
    with open("data/final_dataset.json", "w", encoding="utf-8") as f:
        json.dump(final_logs, f, indent=4, ensure_ascii=False)
    
    with open("data/vulnerabilities.json", "w", encoding="utf-8") as f:
        json.dump(vulnerability_logs, f, indent=4, ensure_ascii=False)

    print(f"\n[DONE] ìœ íš¨ ì·¨ì•½ì  {len(vulnerability_logs)}ê±´ í™•ë³´ ë° ëª¨ë¸ ê°•í™” ì™„ë£Œ.")

if __name__ == "__main__":
    run_pipeline()