import os
import json
import sys
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.detector import SmishingDetector

def evaluate():
    print("=== ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (Model Evaluation) ===")
    
    # 1. ë°ì´í„°ì…‹ ë¡œë“œ
    data_path = os.path.join("data", "test_dataset.json")
    if not os.path.exists(data_path):
        print(f"[!] Error: ë°ì´í„°ì…‹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {data_path}")
        return

    with open(data_path, "r", encoding="utf-8") as f:
        dataset = json.load(f)
    
    print(f"[*] í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: {len(dataset)}ê±´")

    # 2. ëª¨ë¸ ë¡œë“œ
    print("[*] ëª¨ë¸ ë¡œë“œ ì¤‘ (KLUE-RoBERTa)...")
    detector = SmishingDetector()

    # 3. ì˜ˆì¸¡ ì‹¤í–‰
    y_true = []
    y_pred = []
    
    print("[*] ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
    for item in dataset:
        text = item['text']
        true_label = item['label'] # 1=Spam, 0=Ham
        
        # ëª¨ë¸ ì˜ˆì¸¡
        result = detector.predict(text)
        pred_label = 1 if result['is_smishing'] else 0
        
        y_true.append(true_label)
        y_pred.append(pred_label)

    # 4. ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)

    # 5. ê²°ê³¼ ì¶œë ¥ (íŒŒì¼ ì €ì¥ ë° ì½˜ì†” ì¶œë ¥)
    output_lines = []
    output_lines.append("\n" + "="*40)
    output_lines.append(f"âœ… í‰ê°€ ê²°ê³¼ (ë°ì´í„° ê°œìˆ˜: {len(dataset)})")
    output_lines.append("="*40)
    output_lines.append(f"  - ì •í™•ë„ (Accuracy)  : {accuracy:.4f} ({accuracy*100:.1f}%)")
    output_lines.append(f"  - ì •ë°€ë„ (Precision) : {precision:.4f}")
    output_lines.append(f"  - ì¬í˜„ìœ¨ (Recall)    : {recall:.4f}")
    output_lines.append(f"  - F1-Score           : {f1:.4f}")
    output_lines.append("="*40)
    
    output_lines.append("\nğŸ”¸ í˜¼ë™ í–‰ë ¬ (Confusion Matrix):")
    cm = confusion_matrix(y_true, y_pred)
    tn, fp, fn, tp = cm.ravel()
    output_lines.append(f"  [True Negative (ì •ìƒ->ì •ìƒ)]: {tn}")
    output_lines.append(f"  [False Positive (ì •ìƒ->ìŠ¤ë¯¸ì‹±, ì˜¤íƒ)]: {fp}")
    output_lines.append(f"  [False Negative (ìŠ¤ë¯¸ì‹±->ì •ìƒ, ë¯¸íƒ)]: {fn}")
    output_lines.append(f"  [True Positive (ìŠ¤ë¯¸ì‹±->ìŠ¤ë¯¸ì‹±)]: {tp}")

    if fp > 0:
        output_lines.append("\nâš ï¸ ì˜¤íƒ(False Positive) ì‚¬ë¡€ ë¶„ì„ (ì •ìƒì¸ë° ìŠ¤ë¯¸ì‹±ìœ¼ë¡œ ë¶„ë¥˜):")
        cnt = 0
        for i, (t, p) in enumerate(zip(y_true, y_pred)):
            if t == 0 and p == 1:
                output_lines.append(f"  - \"{dataset[i]['text']}\"")
                cnt += 1
                if cnt >= 3: break

    if fn > 0:
        output_lines.append("\nâš ï¸ ë¯¸íƒ(False Negative) ì‚¬ë¡€ ë¶„ì„ (ìŠ¤ë¯¸ì‹±ì¸ë° ì •ìƒìœ¼ë¡œ ë¶„ë¥˜):")
        cnt = 0
        for i, (t, p) in enumerate(zip(y_true, y_pred)):
            if t == 1 and p == 0:
                output_lines.append(f"  - \"{dataset[i]['text']}\"")
                cnt += 1
                if cnt >= 3: break

    result_text = "\n".join(output_lines)
    print(result_text)
    
    with open("eval_result.txt", "w", encoding="utf-8") as f:
        f.write(result_text)
    print("\n[*] ê²°ê³¼ íŒŒì¼ ì €ì¥ ì™„ë£Œ: eval_result.txt")

if __name__ == "__main__":
    evaluate()
